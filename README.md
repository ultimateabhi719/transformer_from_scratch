Transformer Model from Scratch

![transformer.png](https://github.com/ultimateabhi719/transformer_from_scratch/blob/24927be0521f4d741c1f1b5ad9bde7101c20e787/transformer.png)

Transformer Model with Distributed Data Parallel:
- greedy decoding 
- NLL loss criterion

Further Improvements:
- variable batch size merging groups of similar length together to increase training speed
- Take loss = bleu score instead of NLL. To improve performance
- increase model size
- identify better dataset 
